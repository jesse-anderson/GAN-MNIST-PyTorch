{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import torch\n",
    "# import botorch\n",
    "# import pyro   \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device) #GPU?\n",
    "\n",
    "def save_checkpoint(state, filename=\"checkpoint.pth\"):\n",
    "    \"\"\"\n",
    "    Save the training model at the checkpoint.\n",
    "    \"\"\"\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(filename=\"checkpoint.pth\"):\n",
    "    \"\"\"\n",
    "    Load the checkpoint if it exists.\n",
    "    \"\"\"\n",
    "    if os.path.isfile(filename):\n",
    "        return torch.load(filename)\n",
    "    return None\n",
    "\n",
    "def delete_checkpoint(filename=\"checkpoint.pth\"):\n",
    "    \"\"\"\n",
    "    Delete the checkpoint file if it exists, with user confirmation.\n",
    "    \"\"\"\n",
    "    if os.path.isfile(filename):\n",
    "        user_input = input(f\"Are you sure you want to delete '{filename}'? (yes/no): \").lower()\n",
    "        if user_input == 'yes':\n",
    "            os.remove(filename)\n",
    "            print(f\"Checkpoint '{filename}' has been deleted.\")\n",
    "        else:\n",
    "            print(\"Deletion canceled.\")\n",
    "    else:\n",
    "        print(f\"No checkpoint file found at '{filename}' to delete.\")\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import ConcatDataset, Subset, DataLoader\n",
    "from random import sample\n",
    "def adjust_dataset_size(dataset, desired_batch_size):\n",
    "    # Calculate the current size of the dataset\n",
    "    dataset_size = len(dataset)\n",
    "    # Calculate the remainder when dividing the dataset size by the desired batch size squared\n",
    "    remainder = dataset_size % (desired_batch_size ** 2)\n",
    "\n",
    "    # If the remainder is not zero, adjust the dataset size to make it divisible by the desired batch size squared\n",
    "    if remainder != 0:\n",
    "        # Calculate the number of samples to adjust the dataset size\n",
    "        samples_to_adjust = (desired_batch_size ** 2) - remainder\n",
    "\n",
    "        # If more samples are needed, augment the dataset by sampling from it\n",
    "        if samples_to_adjust > 0:\n",
    "            indices = np.random.choice(dataset_size, samples_to_adjust)\n",
    "            additional_dataset = Subset(dataset, indices)\n",
    "\n",
    "            # Combine the original dataset with the additional samples to create an adjusted dataset\n",
    "            adjusted_dataset = ConcatDataset([dataset, additional_dataset])\n",
    "            print(\"Adjusted dataset size: \", len(adjusted_dataset))\n",
    "        \n",
    "        # If fewer samples are needed, trim the dataset to the desired size\n",
    "        else:\n",
    "            adjusted_dataset_size = dataset_size - abs(samples_to_adjust)\n",
    "            adjusted_dataset = Subset(dataset, list(range(adjusted_dataset_size)))\n",
    "    else:\n",
    "        # If the remainder is zero, the dataset size is already divisible by the desired batch size squared\n",
    "        adjusted_dataset = dataset\n",
    "\n",
    "    return adjusted_dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "delete_checkpoint(filename=\"Generator.pth\")\n",
    "delete_checkpoint(filename=\"Discriminator.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "message = 'You can implement the pre-processing transformations, data sets, data loaders, etc. in this cell. \\n'\n",
    "message += '**Important Note**: Read the \"Grading Reference Pre-processing\" bullet, and look at the'\n",
    "message += ' test pre-processing transformations in the \"Autograding and Final Tests\" section before'\n",
    "message += ' training models for long periods of time.'\n",
    "print(message)\n",
    "#Obtained from\n",
    "classes = [str(i) for i in range(10)]  # List of class names from 0 to 9\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "# Hyper-parameters\n",
    "\n",
    "batch_size = 81\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5), std=(0.5,))])\n",
    "\n",
    "# Directory path for the dataset\n",
    "directory_path = '../MNIST'\n",
    "\n",
    "\n",
    "if os.path.exists(directory_path):\n",
    "    print(\"Directory exists.\")\n",
    "else:\n",
    "    print(\"Directory does not exist.\")\n",
    "\n",
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=directory_path, download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3,pin_memory=True) #4 * 1 GPU\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root=directory_path, download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3,pin_memory=True)\n",
    "print('Type of testset: ', type(testset))\n",
    "print('Type of testloader: ', type(testloader))\n",
    "# Adjust the dataset size to make it divisible by the desired batch size\n",
    "trainset = adjust_dataset_size(trainset, batch_size)\n",
    "testset = adjust_dataset_size(testset, batch_size)\n",
    "print(\"Datasets adjusted \")\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4,pin_memory=True) #4 * 1 GPU\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4,pin_memory=True)\n",
    "\n",
    "\n",
    "# Print the size of each dataset and loader\n",
    "print(\"Size of trainset:\", len(trainset))\n",
    "print(\"Size of trainloader:\", len(trainloader.dataset))\n",
    "print(\"Size of testset:\", len(testset))\n",
    "print(\"Size of testloader:\", len(testloader.dataset))\n",
    "print('Type of testset: ', type(testset))\n",
    "print('Type of testloader: ', type(testloader))\n",
    "\n",
    "dataset_size = len(trainset)\n",
    "\n",
    "expected_num_batches = dataset_size // batch_size\n",
    "print(\"Dataset Size: \", dataset_size)\n",
    "print(\"Expected number of batches:\", expected_num_batches)\n",
    "\n",
    "# Inspect the trainloader\n",
    "print(\"Size of trainset:\", len(trainset))\n",
    "print(\"Size of trainloader:\", len(trainloader))\n",
    "\n",
    "# Extract a single batch from the DataLoader\n",
    "inputs, labels = next(iter(trainloader))\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "# Print shapes directly using PyTorch without converting to NumPy\n",
    "print(\"Shape of inputs (batch):\", inputs.shape)  # [batch_size, channels, height, width]\n",
    "print(\"Shape of labels (batch):\", labels.shape)  # [batch_size]\n",
    "\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "img, label = trainset[0]\n",
    "print('Label: ', label)\n",
    "print(img[:,10:15,10:15])\n",
    "torch.min(img), torch.max(img)\n",
    "\n",
    "img_norm = denorm(img)\n",
    "plt.imshow(img_norm[0], cmap='gray')\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'You can visualize some of the pre-processed images here (This is optional and only for your own reference).'\n",
    "print(message)\n",
    "\n",
    "# your code here\n",
    "# raise NotImplementedError\n",
    "\n",
    "# # Source: Tutorial at https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:81], nrow=9))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = inputs.shape[3]*inputs.shape[2]\n",
    "# image_size = 784\n",
    "print(image_size)\n",
    "hidden_size = 256\n",
    "latent_size = 64\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "                            nn.Linear(latent_size, hidden_size),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(hidden_size, hidden_size),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(hidden_size, image_size),\n",
    "                            nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.net(x)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "                            nn.Linear(image_size, hidden_size),\n",
    "                            nn.LeakyReLU(0.2),\n",
    "                            nn.Linear(hidden_size, hidden_size),\n",
    "                            nn.LeakyReLU(0.2),\n",
    "                            nn.Linear(hidden_size, 1),\n",
    "                            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.net(x)\n",
    "\n",
    "Gen = Generator()\n",
    "Disc= Discriminator()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device) #GPU?\n",
    "\n",
    "Gen = Generator().to(device)\n",
    "Disc = Discriminator().to(device)\n",
    "print(device)\n",
    "\n",
    "y = Gen(torch.randn(2, latent_size,device='cuda'))\n",
    "y\n",
    "gen_imgs = denorm(y.reshape((-1, 28,28)).detach())\n",
    "plt.imshow(gen_imgs[0].cpu(), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "lr_d=0.0002\n",
    "lr_g=0.0002\n",
    "\n",
    "d_optimizer = torch.optim.Adam(Disc.parameters(), lr=lr_d)\n",
    "g_optimizer = torch.optim.Adam(Gen.parameters(), lr=lr_g)\n",
    "\n",
    "def reset_grad():\n",
    "    d_optimizer.zero_grad()\n",
    "    g_optimizer.zero_grad()\n",
    "\n",
    "def train_discriminator(images):\n",
    "    # Create the labels which are later used as input for the BCE loss\n",
    "    real_labels = torch.ones(batch_size, 1).to(device)\n",
    "    fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "    # Loss for real images\n",
    "    outputs = Disc(images)\n",
    "    d_loss_real = criterion(outputs, real_labels)\n",
    "    real_score = outputs\n",
    "\n",
    "    # Loss for fake images\n",
    "    z = torch.randn(batch_size, latent_size).to(device)\n",
    "    fake_images = Gen(z)\n",
    "    outputs = Disc(fake_images)\n",
    "    d_loss_fake = criterion(outputs, fake_labels)\n",
    "    fake_score = outputs\n",
    "\n",
    "    # Combine losses\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    # Reset gradients\n",
    "    reset_grad()\n",
    "    # Compute gradients\n",
    "    d_loss.backward()\n",
    "    # Adjust the parameters using backprop\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    return d_loss, real_score, fake_score, fake_images\n",
    "\n",
    "def train_generator():\n",
    "    # Generate fake images and calculate loss\n",
    "    z = torch.randn(batch_size, latent_size).to(device)\n",
    "    fake_images = Gen(z)\n",
    "    labels = torch.ones(batch_size, 1).to(device)\n",
    "    g_loss = criterion(Disc(fake_images), labels)\n",
    "\n",
    "    # Backprop and optimize\n",
    "    reset_grad()\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    return g_loss\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def concatenate_figures_horizontally(figures, output_file_name):\n",
    "    # Specify the directory to save plots\n",
    "    output_directory = './plots'\n",
    "    # Create the directory if it does not exist\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    \n",
    "    # Full path for the output file\n",
    "    output_path = os.path.join(output_directory, output_file_name)\n",
    "\n",
    "    images = []\n",
    "    for fig in figures:\n",
    "        # Save the figure to a bytes buffer\n",
    "        buf = BytesIO()\n",
    "        fig.savefig(buf, format='png', bbox_inches='tight')  # Use bbox_inches='tight' to reduce excess whitespace\n",
    "        buf.seek(0)\n",
    "        # Load the image into PIL and make a copy\n",
    "        img = Image.open(buf).copy()  # Make a copy of the image data\n",
    "        images.append(img)\n",
    "        buf.close()  # Now you can safely close the buffer\n",
    "\n",
    "    # Calculate total width and max height\n",
    "    total_width = sum(img.width for img in images)\n",
    "    max_height = max(img.height for img in images)\n",
    "\n",
    "    # Create a new image with the appropriate size\n",
    "    new_image = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "    # Paste images into new image\n",
    "    x_offset = 0\n",
    "    for img in images:\n",
    "        new_image.paste(img, (x_offset, 0))\n",
    "        x_offset += img.width\n",
    "        img.close()  # Close each image object to free memory\n",
    "\n",
    "    # Save the new image\n",
    "    # print(f'Saving graphs to {output_path}...')\n",
    "    new_image.save(output_path)\n",
    "    new_image.close()  # Close the final concatenated image\n",
    "\n",
    "def plot_training_progress(real_images, fake_images, d_losses, g_losses, real_scores, fake_scores, lr_d,lr_g,epoch,epochChunk):\n",
    "    figures=[]\n",
    "    # Plot real and fake images side by side\n",
    "    fig0 = plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Real Images\")\n",
    "    plt.imshow(real_images[0].detach().cpu().numpy().reshape(28,28), cmap='gray')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Fake Images\")\n",
    "    plt.imshow(fake_images[0].detach().cpu().numpy().reshape(28,28), cmap='gray')\n",
    "\n",
    "\n",
    "    # Plot d_losses and g_losses\n",
    "    fig1 = plt.figure(figsize=(10,5))\n",
    "    plt.plot(d_losses, label='Discriminator Loss', linewidth=4)\n",
    "    plt.plot(g_losses, label='Generator Loss', linewidth=4)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Discriminator and Generator Losses')\n",
    "\n",
    "    figures.append(fig1)\n",
    "\n",
    "    # Plot real_scores and fake_scores\n",
    "    fig2= plt.figure(figsize=(10,5))\n",
    "    plt.plot(real_scores, label='Real Score', linewidth=3.5)\n",
    "    plt.plot(fake_scores, label='Fake Score', linewidth=4)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.title('Real and Fake Scores')\n",
    "\n",
    "    figures.append(fig2)\n",
    "\n",
    "    # Plot learning_rates\n",
    "    fig3 = plt.figure(figsize=(10,5))\n",
    "    plt.plot(lr_d, label='Discriminator Learning Rate', linewidth=4)\n",
    "    plt.plot(lr_g, label='Generator Learning Rate', linewidth=4)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.title('Learning Rate')\n",
    "    if epoch % epochChunk == 0:\n",
    "        plt.show()\n",
    "    figures.append(fig3)\n",
    "    output_path = 'Graphs-{0:0=4d}.png'.format(epoch)\n",
    "    concatenate_figures_horizontally(figures, output_path)\n",
    "\n",
    "    # Optionally show figures if needed\n",
    "    figures[:0] = [fig0]\n",
    "    if epoch % epochChunk == 0:\n",
    "        for fig in figures:\n",
    "            plt.figure(fig.number)  # Switch to figure\n",
    "            plt.show()\n",
    "    for fig in figures:\n",
    "        plt.close(fig)  # Ensure figures are closed properly\n",
    "\n",
    "sample_vectors = torch.randn(batch_size, latent_size).to(device)\n",
    "def save_fake_images(index):\n",
    "    fake_images = Gen(sample_vectors)\n",
    "    # Assuming fake_images is a batch of flattened grayscale images with shape [batch_size, 784]\n",
    "    fake_images = fake_images.view(-1, 1, 28, 28)  # Reshape to [batch_size, 1, 28, 28]\n",
    "    # print(\"Reshaped fake_images:\", fake_images.shape)\n",
    "    \n",
    "    # Resize the fake images to be twice as large with bicubic interpolation\n",
    "    fake_images = F.interpolate(fake_images, size=(112,112), mode='bicubic')\n",
    "    fake_fname = 'fake_images-{0:0=4d}.png'.format(index)\n",
    "    # print('Saving', fake_fname)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=9, format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Load checkpoint if it exists\n",
    "checkpoint1 = load_checkpoint(\"Generator.pth\")\n",
    "\n",
    "if checkpoint1:\n",
    "    print('Generator.pth Loaded')\n",
    "    Gen.load_state_dict(checkpoint1['model_state_dict'])\n",
    "    g_optimizer.load_state_dict(checkpoint1['optimizer_state_dict'])  # Load optimizer for generator\n",
    "    start_epoch = checkpoint1['epoch']\n",
    "    d_losses = checkpoint1['d_losses']\n",
    "    g_losses = checkpoint1['g_losses']\n",
    "    real_scores = checkpoint1['real_scores']\n",
    "    fake_scores = checkpoint1['fake_scores']\n",
    "    lr_d_scores = checkpoint1['lr_d_scores']\n",
    "    lr_g_scores = checkpoint1['lr_g_scores']\n",
    "else:\n",
    "    start_epoch = 1\n",
    "    d_losses, g_losses, real_scores, fake_scores, lr_g_scores, lr_d_scores = [], [], [], [], [], []\n",
    "    del checkpoint1\n",
    "\n",
    "\n",
    "checkpoint2 = load_checkpoint(\"Discriminator.pth\")\n",
    "if checkpoint2:\n",
    "    print('Discriminator.pth Loaded')\n",
    "    Disc.load_state_dict(checkpoint2['model_state_dict'])\n",
    "    d_optimizer.load_state_dict(checkpoint2['optimizer_state_dict'])  # Load optimizer for generator\n",
    "    start_epoch = checkpoint2['epoch']\n",
    "    d_losses = checkpoint2['d_losses']\n",
    "    g_losses = checkpoint2['g_losses']\n",
    "    real_scores = checkpoint2['real_scores']\n",
    "    fake_scores = checkpoint2['fake_scores']\n",
    "    lr_d_scores = checkpoint2['lr_d_scores']\n",
    "    lr_g_scores = checkpoint2['lr_g_scores']\n",
    "else:\n",
    "    start_epoch = 1\n",
    "    d_losses, g_losses, real_scores, fake_scores, lr_g_scores, lr_d_scores = [], [], [], [], [], []\n",
    "    del checkpoint2\n",
    "num_epochs = 540\n",
    "epochChunk = 40\n",
    "total_step = len(trainloader)\n",
    "\n",
    "print(\"Length of trainloader:\", len(trainloader))\n",
    "print(\"Length of trainset:\", len(trainset))\n",
    "\n",
    "for epoch in range(start_epoch,num_epochs):\n",
    "    start_time = time.time()  # Start time of the epoch\n",
    "    # batch_count = 0\n",
    "    for i, (images, _) in enumerate(trainloader):\n",
    "        # Load a batch & transform to vectors\n",
    "        # batch_count += 1\n",
    "        # print(\"Batch:\", batch_count)\n",
    "        # print(\"Batch size:\", images.shape)\n",
    "        # images = images.reshape(batch_size, -1)\n",
    "        # print(i)\n",
    "        # print(images.shape)\n",
    "        images = images.reshape(batch_size, -1).to(device)\n",
    "        \n",
    "        # Train the discriminator and generator\n",
    "        d_loss, real_score, fake_score,fake_images = train_discriminator(images)\n",
    "        g_loss = train_generator()\n",
    "        \n",
    "        # Inspect the losses\n",
    "        if (i+1) % 500 == 0:\n",
    "           \n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n",
    "                          real_score.mean().item(), fake_score.mean().item()))\n",
    "    d_losses.append(d_loss.item())\n",
    "    g_losses.append(g_loss.item())\n",
    "    real_scores.append(real_score.mean().item())\n",
    "    fake_scores.append(fake_score.mean().item())\n",
    "    lr_g_scores.append(lr_g)\n",
    "    lr_d_scores.append(lr_d)\n",
    "\n",
    "    d_lossAvg = d_loss / len(trainloader.dataset)\n",
    "    g_lossAvg = g_loss / len(trainloader.dataset)\n",
    "    fake_scoreAvg = fake_score / len(trainloader.dataset)\n",
    "    real_scoreAvg = real_score / len(trainloader.dataset)\n",
    "    \n",
    "    plot_training_progress(images, fake_images, d_losses, g_losses, real_scores, fake_scores, lr_g_scores,lr_d_scores,epoch,epochChunk)\n",
    "\n",
    "    # Calculate duration and print\n",
    "    epoch_duration = time.time() - start_time\n",
    "    print(f\"Epoch {epoch} completed in {epoch_duration:.2f} seconds\")\n",
    "\n",
    "    save_checkpoint({\n",
    "    'epoch': epoch + 1,\n",
    "    'model_state_dict': Disc.state_dict(),\n",
    "    'optimizer_state_dict': d_optimizer.state_dict(),\n",
    "    'd_losses': d_losses,\n",
    "    'g_losses': g_losses,\n",
    "    'real_scores': real_scores,\n",
    "    'fake_scores': fake_scores,\n",
    "    'lr_d_scores': lr_d_scores,\n",
    "    'lr_g_scores': lr_g_scores\n",
    "}, \"Discriminator.pth\")\n",
    "    save_checkpoint({\n",
    "    'epoch': epoch + 1,\n",
    "    'model_state_dict': Gen.state_dict(),\n",
    "    'optimizer_state_dict': g_optimizer.state_dict(),\n",
    "    'd_losses': d_losses,\n",
    "    'g_losses': g_losses,\n",
    "    'real_scores': real_scores,\n",
    "    'fake_scores': fake_scores,\n",
    "    'lr_d_scores': lr_d_scores,\n",
    "    'lr_g_scores': lr_g_scores\n",
    "}, \"Generator.pth\")\n",
    "    save_fake_images(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the checkpoint file\n",
    "# checkpoint = torch.load(\"Generator.pth\")\n",
    "# print(epoch)\n",
    "# # Print keys and values in the checkpoint dictionary\n",
    "# for key, value in checkpoint.items():\n",
    "#     print(key, \": \", value)\n",
    "\n",
    "import cv2\n",
    "def concatenate_images_vertically(fake_img_path, graph_img_path, output_dir):\n",
    "    # Load the fake image and graph image\n",
    "    fake_image = Image.open(fake_img_path)\n",
    "    graph_image = Image.open(graph_img_path)\n",
    "\n",
    "    # Resize graph image to match the width of the fake image\n",
    "    width_fake_image = fake_image.width\n",
    "    aspect_ratio = graph_image.height / graph_image.width\n",
    "    new_height = int(width_fake_image * aspect_ratio)\n",
    "    graph_image_resized = graph_image.resize((width_fake_image, new_height), Image.ANTIALIAS)\n",
    "\n",
    "    # Concatenate images vertically\n",
    "    total_height = fake_image.height + graph_image_resized.height\n",
    "    new_image = Image.new('RGB', (width_fake_image, total_height))\n",
    "    new_image.paste(fake_image, (0, 0))\n",
    "    new_image.paste(graph_image_resized, (0, fake_image.height))\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Construct the output path and save the concatenated image\n",
    "    base_filename = os.path.basename(fake_img_path)\n",
    "    output_path = os.path.join(output_dir, base_filename.replace('fake_images', 'image_plot_combined'))\n",
    "    new_image.save(output_path)\n",
    "    return output_path\n",
    "\n",
    "def create_video(image_folder, output_video_file, output_dir):\n",
    "    # Ensure output directory for the video exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created directory {output_dir} for output video.\")\n",
    "\n",
    "    output_video_path = os.path.join(output_dir, output_video_file)\n",
    "\n",
    "    # Check if the image directory exists and is not empty\n",
    "    if not os.path.exists(image_folder) or not os.listdir(image_folder):\n",
    "        print(f\"Directory {image_folder} does not exist or is empty.\")\n",
    "        return  # Exit the function if no files to process\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    files = [os.path.join(image_folder, f) for f in sorted(os.listdir(image_folder)) if 'image_plot_combined' in f]\n",
    "\n",
    "    if not files:\n",
    "        print(\"No files found in the directory.\")\n",
    "        return  # Exit if no files found\n",
    "\n",
    "    frame = cv2.imread(files[0])\n",
    "    if frame is None:\n",
    "        print(f\"Could not read the first file: {files[0]}\")\n",
    "        return  # Check if the first file can be read properly\n",
    "\n",
    "    height, width, layers = frame.shape\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, 8, (width, height))\n",
    "\n",
    "    for file in files:\n",
    "        frame = cv2.imread(file)\n",
    "        if frame is not None:\n",
    "            out.write(frame)  # Write out frame to video\n",
    "        else:\n",
    "            print(f\"Skipping file, cannot read: {file}\")\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Video created successfully: {output_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# from IPython.display import FileLink\n",
    "\n",
    "# vid_fname = 'MNIST_GAN_Training.avi'\n",
    "\n",
    "# files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'fake_images' in f]\n",
    "# files.sort()\n",
    "\n",
    "# out = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 8, (302,302))\n",
    "# [out.write(cv2.imread(fname)) for fname in files]\n",
    "# out.release()\n",
    "# FileLink('gans_training.avi')\n",
    "\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Paths\n",
    "sample_dir_fake = 'samples'  # Directory containing fake images\n",
    "sample_dir_graphs = 'plots'  # Directory containing graph images\n",
    "combined_images = 'img_plot_combined'\n",
    "combined_images_dir = 'video'  # Directory for combined images\n",
    "\n",
    "# Prepare file lists\n",
    "fake_images = [f for f in sorted(os.listdir(sample_dir_fake)) if 'fake_images' in f]\n",
    "graph_images = [f for f in sorted(os.listdir(sample_dir_graphs)) if 'Graphs' in f]\n",
    "print(len(fake_images))\n",
    "\n",
    "print(len(graph_images))\n",
    "# Assume that fake_images and graph_images are aligned correctly\n",
    "for fake_img, graph_img in zip(fake_images, graph_images):\n",
    "    fake_img_path = os.path.join(sample_dir_fake, fake_img)\n",
    "    graph_img_path = os.path.join(sample_dir_graphs, graph_img)\n",
    "    concatenate_images_vertically(fake_img_path, graph_img_path,combined_images)\n",
    "\n",
    "# Create video from combined images\n",
    "vid_fname = 'MNIST_GAN_Training.avi'\n",
    "create_video(combined_images, vid_fname,combined_images_dir)\n",
    "\n",
    "# Optionally, provide a link to download the video (in Jupyter Notebook)\n",
    "FileLink('video/' + vid_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, provide a link to download the video (in Jupyter Notebook)\n",
    "FileLink('video/' + vid_fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
